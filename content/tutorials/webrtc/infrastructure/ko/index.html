{% extends "tutorial.html" %}

{% block pagebreadcrumb %}{{ tut.title }}{% endblock %}

{% block html5badge %}
<img src="/static/images/identity/html5-badge-h-multimedia.png" width="133" height="64" alt="This article is powered by HTML5 Audio/Video" title="This article is powered by HTML5 Audio?/Video" />
{% endblock %}

{% block iscompatible %}
return !! (window.RTCPeerConnection || window.webkitDeprecatedPeerConnection || window.webkitRTCPeerConnection);
{% endblock %}

{% block head %}
<style>
.talkinghead:before {
  background-image: url(/static/images/profiles/75/dutton.75.png);
  background-position: 0px 0px !important;
}
</style>
{% endblock %}

{% block onload %}
// TODO
{% endblock %}

{% block content %}

<blockquote class="commentary talkinghead">

  <p>WebRTC는 P2P 통신을 가능하게 합니다.<!-- WebRTC enables peer to peer communication. --></p>

  <p>그러나<!-- BUT -->...</p>

  <p>WebRTC는 여전히 다음과 같은 서버를 필요로 합니다.<!-- WebRTC still needs servers: --></p>

  <ul>
    <li>클라이언트들의 통신을 조정하기 위한 메타데이터의 교환. 이것은 시그널링(Signaling)이라고 불립니다.<!-- For clients to exchange metadata to coordinate communication: this is called signaling. --></li>
    <li>네트워크 주소 변환기 (NAT를) 및 방화벽에 대한 대응.<!-- To cope with network address translators (NATs) and firewalls. --></li>
  </ul>


</blockquote>

<p>이 글에서 우리는 여러분에게 시그널링 서비스를 어떻게 구축하는지와 STUN과 TURN 서버들을 이용하여 실제 연결에 있어 이상한 사항들에 대해 어떻게 타협해야 하는지를 보여줄 것입니다. 또한 WebRTC 앱들이 어떻게 다단위의 호출을 제어할 수 있는지와 VoIP나 PSTN(전화라고도 하는)과 같은 서비스들과 어떻게 상호작용하는지에 대해 설명할 것입니다.<!-- In this article we show you how to build a signaling service, and how to deal with the quirks of real-world connectivity by using STUN and TURN servers. We also explain how WebRTC apps can handle multi-party calls and interact with services such as VoIP and PSTN (aka telephones). --></p>

<p>만약 여러분이 WebRTC의 기초에 대해 익숙하지 않다면, 이 글을 읽기 전에 <a href="http://www.html5rocks.com/en/tutorials/webrtc/basics/">WebRTC와 함께 시작하기</a>를 찾아서 읽어보기를 강력하게 권장합니다.<!-- If you're not familiar with the basics of WebRTC, we strongly recommend you take a look at <a href="http://www.html5rocks.com/en/tutorials/webrtc/basics/">Getting Started With WebRTC</a> before reading this article. --></p>

<h2 id="what-is-signaling">시그널링(Signaling)이란 무엇인가?<!-- What is signaling? --></h2>

<p>시그널링은 통신 조정의 프로세스입니다. WebRTC 어플리케이션이 'call'을 초기화하기 위해서 클라이언트는 다음과 같은 정보의 교환을 필요로 합니다.<!-- Signaling is the process of coordinating communication. In order for a WebRTC application to set up a 'call', its clients need to exchange information: --></p>

<ul>
  <li>통신을 열고 닫는데 사용되는 세션 컨트롤 메세지들.<!-- Session control messages used to open or close communication. --></li>
  <li>에러 메세지들.<!-- Error messages. --></li>
  <li>코덱이나 코덱 설정, 대역폭, 미디어 타입 같은 미디어 메타데이터.<!-- Media metadata such as codecs and codec settings, bandwidth and media types. --></li>
  <li>보안 연결을 수립하기 위해 사용되는 키 데이터.<!-- Key data, used to establish secure connections. --></li>
  <li>밖에서 보이는 것처럼 호스트의 IP 주소와 포트와 같은 네트워크 데이터.<!-- Network data, such as a host's IP address and port as seen by the outside world. --></li>
</ul>

<p>이 시그널링 프로세스는 클라이언트에서 메세지를 앞/뒤로 전달하기 위한 방법을 필요로 합니다. 그 메커니즘은 WebRTC API에 의해 구현되지 않습니다. 여러분이 직접 구축하여야 합니다. 시그널링 서비스 구축을 위한 몇가지 방법을 아래에 기술할 것입니다. 그러나 그 전에 아주 작은 것부터 설명하도록 하겠습니다...<!-- This signaling process needs a way for clients to pass messages back and forth. That mechanism is not implemented by the WebRTC APIs: you need to build it yourself. We describe below some ways to build a signaling service. First, however, a little context... --></p>

<h3 id="jsep">JSEP</h3>

<p>중복의 회피와 호환성을 최대화하기 위해 기술, 시그널링 방법 그리고 프로토콜의 설정은 WebRTC 표준 규격에 정의되어 있지 않습니다. 이 접근 방식은 다음과 같이 <a href="http://tools.ietf.org/html/draft-ietf-rtcweb-jsep-03#section-1.1">JavaScript Session Establishment Protocol</a>(JSEP)에 의해 설명할 수 있습니다.<!-- To avoid redundancy and to maximize compatibility with established technologies, signaling methods and protocols are not specified by WebRTC standards. This approach is outlined by JSEP, the <a href="http://tools.ietf.org/html/draft-ietf-rtcweb-jsep-03#section-1.1">JavaScript Session Establishment Protocol</a>: --></p>

<blockquote class="commentary">WebRTC call 설정은 완전하게 규격화되어 미디어 plane을 제어하지만 어플리케이션에 가능한한 최대의 시그널링 증가를 방지해야 합니다. 기존의 SIP나 Jingle call 시그널링 프로토콜, 혹은 소설 적용 사례같은 특정 어플리케이션이 특화된 무언가 다른 프로토콜을 사용에 적합한 다른 어플리케이션들이 그 근거일 것입니다. 이러한 접근에서 교환되어야 할 핵심 정보들은 요구되는 송수신과 미디어 plane을 설정하기 위한 미디어 설정 정보를 구성하는데 필요한 멀티미디어 세션 설명(Description) 정보입니다.<!-- The thinking behind WebRTC call setup has been to fully specify and control the media plane, but to leave the signaling plane up to the application as much as possible. The rationale is that different applications may prefer to use different protocols, such as the existing SIP or Jingle call signaling protocols, or something custom to the particular application, perhaps for a novel use case. In this approach, the key information that needs to be exchanged is the multimedia session description, which specifies the necessary transport and media configuration information necessary to establish the media plane. --></blockquote>

<p>또한 JSEP의 구조는 브라우저가 상태를 저장하는 것을 회피합니다. (즉, 시그널링 상태 기계로써 함수에 전달하는 경우.) 이 경우도 문제가 있을 수 있습니다. 시그널링 데이터가 페이지가 리로딩되면서 매번 사라지는 경우가 그 예입니다. 대신 시그널링 상태는 서버에 저장될 수 있습니다.<!-- JSEP's architecture also avoids a browser having to save state: that is, to function as a signaling state machine. This would be problematic if, for example, signaling data was lost each time a page was reloaded. Instead, signaling state can be saved on a server. --></p>

<figure>
  <img src="jsep.png" alt="JSEP architecture diagram" />
  <figcaption>JSEP 구조<!-- JSEP architecture --></figcaption>
</figure>

<p>JESP는 다음과 같이 <em>제안</em>과 <em>응답</em>의 종단(Peer)간의 교환이 필요합니다.위에서 언급한 미디어 메타데이터. 제안들과 응답들은 다음과 같은 '세션 기술 프로토콜(SDP)' 형식입니다.<!-- JSEP requires the exchange between peers of <em>offer</em> and <em>answer</em>: the media metadata mentioned above. Offers and answers are communicated in Session Description Protocol format (SDP), which look like this: --></p>

<pre class="prettyprint">v=0
o=- 7614219274584779017 2 IN IP4 127.0.0.1
s=-
t=0 0
a=group:BUNDLE audio video
a=msid-semantic: WMS
m=audio 1 RTP/SAVPF 111 103 104 0 8 107 106 105 13 126
c=IN IP4 0.0.0.0
a=rtcp:1 IN IP4 0.0.0.0
a=ice-ufrag:W2TGCZw2NZHuwlnf
a=ice-pwd:xdQEccP40E+P0L5qTyzDgfmW
a=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-level
a=mid:audio
a=rtcp-mux
a=crypto:1 AES_CM_128_HMAC_SHA1_80 inline:9c1AHz27dZ9xPI91YNfSlI67/EMkjHHIHORiClQe
a=rtpmap:111 opus/48000/2
…</pre>

<p>이 모든 SDP의 까다로운 표현들이 실제로 무엇을 의미하는지 알고 싶으십니까? 그렇다면 <a href="http://datatracker.ietf.org/doc/draft-nandakumar-rtcweb-sdp/?include_text=1">IETF 예제들</a>을 살펴보시기 바랍니다.<!-- Want to know what all this SDP gobbledygook actually means? Take a look at the <a href="http://datatracker.ietf.org/doc/draft-nandakumar-rtcweb-sdp/?include_text=1">IETF examples</a>. --></p>

<p>WebRTC는 제안이나 응답은 로컬이나 원격 기술(Description)로 설정되기 전에 SDP 텍스트에서 값의 편집을 통해 변경될 수 있도록 디자인되었음을 명심하여야 합니다. 예를 들어 <a href="https://apprtc.appspot.com/js/main.js">apprtc.appspot.com</a>의 <em>preferAudioCodec()</em> 함수는 기본 코덱과 비트레이트를 설정하기 위해 사용할 수 있습니다. SDP는 자바스크립트로 관리하기에 조금은 고통스럽고 WebRTC의 향후 버전은 대신 JSON을 사용하도록 하자는 논의가 있지만 SDP와 붙어있음으로 인한 <a href="http://tools.ietf.org/html/draft-ietf-rtcweb-jsep-03#section-3.3">몇가지 이점들</a>이 있습니다.<!-- Bear in mind that WebRTC is designed so that the offer or answer can be tweaked before being set as the local or remote description, by editing the values in the SDP text. For example, the <em>preferAudioCodec() </em>function in <a href="https://apprtc.appspot.com/js/main.js">apprtc.appspot.com</a> can be used to set the default codec and bitrate. SDP is somewhat painful to manipulate with JavaScript, and there is discussion about whether future versions of WebRTC should use JSON instead, but there are <a href="http://tools.ietf.org/html/draft-ietf-rtcweb-jsep-03#section-3.3">some advantages</a> to sticking with SDP. --></p>

<h3 id="rtcpeerconnection-signaling-offer-answer-and-candidate">RTCPeerConnection + 시그널링 : 제안, 응답 그리고 후보<!-- RTCPeerConnection + signaling: offer, answer and candidate --></h3>

<p>RTCPeerConnection은 WebRTC 어플리케이션이 Peer 간의 연결을 생성하고 오디오와 비디오의 통신에 사용되는 API입니다.<!-- RTCPeerConnection is the API used by WebRTC applications to create a connection between peers and communicate audio and video. --></p>

<p>이 프로세스를 초기화하기 위해 RTCPeerConnection는 다음과 같은 2가지 태스크를 가지고 있습니다.<!-- To initialise this process RTCPeerConnection has two tasks: --></p>

<ul>
  <li>해상도나 가용한 코덱 정보 등의 로컬 미디어 상태들을 알아냅니다. 이것은 제안/응답 메커니즘에서 사용되는 메타데이터입니다.<!-- Ascertain local media conditions, such as resolution and codec capabilities. This is the metadata used for the offer and answer mechanism. --></li>
  <li><em>후보들</em>로 알려진 어플리케이션 호스트의 잠재적인 네트워크 주소들을 가져옵니다.<!-- Get potential network addresses for the application's host, known as <em>candidates</em>. --></li>

</ul>

<p>일단 로컬 데이터가 알아내지면, 시그널링 메커니즘를 통해 리모트 Peer와 반드시 교환되어야 합니다.<!-- Once this local data has been ascertained, it must be exchanged via a signaling mechanism with the remote peer. --></p>

<p><a href="http://xkcd.com/177/">앨리스가 이브를 부르려고 시도하는 것</a>을 상상해 보시기 바랍니다. 완전한 제안/응답 메커니즘에 대한 이런저런 뒷얘기들을 얘기하도록 하겠습니다.<!-- Imagine <a href="http://xkcd.com/177/">Alice is trying to call Eve</a>. Here's the full offer/answer mechanism in all its gory detail: --></p>

<ol style="list-style-type: decimal">
  <li>앨리스가 RTCPeerConnection 객체를 생성합니다.<!-- Alice creates an RTCPeerConnection object. --></li>
  <li>앨리스가 <em>createOffer()</em> 메소드를 사용하여 <stong>제안</strong>(SDP Session Description)을 생성합니다.<!-- Alice creates an <strong>offer</strong> (an SDP session description) with the RTCPeerConnection <em>createOffer() </em>method. --></li>
  <li>앨리스가 제안과 함께 <em>setLocalDescription()</em>를 호출합니다.<!-- Alice calls <em>setLocalDescription() </em>with his offer. --></li>
  <li><p>앨리스는 제안을 문자열화하고 시그널링 메커니즘을 이용하여 이브에게 보냅니다.<!-- Alice stringifies the offer and uses a signaling mechanism to send it to Eve. --></p></li>
  <li>이브는 앨리스의 제안을 가지고 <em>setRemoteDescription()</em>를 호출하였으므로 그녀의 RTCPeerConnection가 앨리스의 설정을 알게됩니다.<!-- Eve calls <em>setRemoteDescription()</em> with Alice's offer, so that her RTCPeerConnection knows about Alice's setup. --></li>
  <li>이브는 em>createAnswer()</em>를 호출하고 이에 대해 로컬 세션 정보(Local Session Description), 즉 이브의 <strong>응답</strong>을 인자로 전달하는 성공 콜백 함수를 호출합니다.<!-- Eve calls <em>createAnswer()</em>, and the success callback for this_ _is passed a local session description: Eve's <strong>answer</strong>. --></li>
  <li>이브는 <em>setLocalDescription()</em>의 호출을 통해 그녀의 응답을 로컬 기술(Description)으로 설정합니다.<!-- Eve sets her answer as the local description by calling <em>setLocalDescription()</em>. --></li>
  <li>그리고나서 이브는 시그널링 메커니즘을 사용하여 그녀의 문자열화된 응답을 앨리스에게 다시 전송합니다.<!-- Eve then uses the signaling mechanism to send her stringified answer back to Alice. --></li>
  <li><p>앨리스는 <em>setRemoteDescription()</em>을 사용하여 이브의 응답을 원격 세션 기술(Description)으로 설정합니다.<!-- Alice sets Eve's answer as the remote session description using <em>setRemoteDescription()</em>. --></p></li>
</ol>

<!-- flow diagram -->

<blockquote class="commentary talkinghead">
  <p><a href="http://www.urbandictionary.com/define.php?term=strewth">맙소사!<!-- Strewth --></a>!</p>
</blockquote>

<p>앨리스와 이브는 또한 네트워크 정보의 교환이 필요합니다. '후보들의 발견' 표시는 네트워크 인터페이스의 탐색 절차와 <a href="http://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment">ICE framework</a>를 사용한 포팅과 관련이 있습니다.<!-- Alice and Eve also need to exchange network information. The expression 'finding candidates' refers to the process of finding network interfaces and ports using the <a href="http://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment">ICE framework</a>. --></p>

<ol style="list-style-type: decimal">
  <li>앨리스는 <em>onicecandidate</em> 핸들러를 가진 RTCPeerConnection 객체를 생성합니다.<!-- Alice creates an RTCPeerConnection object with an <em>onicecandidate</em> handler. --></li>
  <li>핸들러는 네트워크가 가용 대기 상태가 되면 호출됩니다.<!-- The handler is called when network candidates become available. --></li>
  <li>핸들러에서 앨리스는 이브에게 그들의 시그널링 채널을 통해 문자열화된 후보 데이터를 전송합니다.<!-- In the handler, Alice sends stringified candidate data to Eve, via their signaling channel. --></li>
  <li>이브가 후보 메세지를 앨리스로부터 수신할 때 원격 Peer 기술(Description)으로의 후보를 추가하는 <em>addIceCandidate()</em>를 호출합니다.<!-- When Eve gets a candidate message from Alice, she calls <em>addIceCandidate()</em>, to add the candidate to the remote peer description. --></li>
</ol>

<p>JSEP는 초기 제안 뒤에 피호출자에 대한 후보들을 증분 제공하는 호출자를 가능하게 하는<a href="http://tools.ietf.org/html/draft-ietf-rtcweb-jsep-03#section-3.4.1">ICE Candidate Trickling</a>와 피호출자에게 호출시 동작을 시작하고 도착한 모든 호부들에 대한 대기없이 연결을 설정할 수 있는 기능을 지원하고 있습니다.<!-- JSEP supports <a href="http://tools.ietf.org/html/draft-ietf-rtcweb-jsep-03#section-3.4.1">ICE Candidate Trickling</a>, which allows the caller to incrementally provide candidates to the callee after the initial offer, and for the callee to begin acting on the call and setting up a connection without waiting for all candidates to arrive. --></p>

<h3 id="coding-webrtc-for-signaling">시그널링을 위한 WebRTC 코딩하기<!-- Coding WebRTC for signaling --></h3>

<p>아래는 완전한 시그널링 프로세스를 요약한 <a href="http://www.w3.org/TR/webrtc/#simple-peer-to-peer-example">W3C 코드 예제</a>입니다. 코드는 <em>SignalingChannel</em> 같은 어떤 시그널링 메커니즘이 존재하고 있다고 가정합니다. 시그널링은 아래에서 훨씬 더 자세하게 논의하도록 하겠습니다.<!-- Below is a <a href="http://www.w3.org/TR/webrtc/#simple-peer-to-peer-example">W3C code example</a> that summarises the complete signaling process. The code assumes the existence of some signaling mechanism, <em>SignalingChannel</em>. Signaling is discussed in greater detail below. --></p>

<pre class="prettyprint">var signalingChannel = new SignalingChannel();
var configuration = {
  'iceServers': [{
    'url': 'stun:stun.example.org'
  }]
};
var pc;

// 초기화하려면 start()를 호출합니다.<!-- call start() to initiate -->

function start() {
  pc = new RTCPeerConnection(configuration);

  // 다른 Peer에 대한 ICE 후보들을 전송합니다. <!-- send any ice candidates to the other peer -->
  pc.onicecandidate = function (evt) {
    if (evt.candidate)
      signalingChannel.send(JSON.stringify({
        'candidate': evt.candidate
      }));
  };

  // '제안'이 생성되면 'negotiationneeded' 이벤트를 발생합니다. <!-- let the 'negotiationneeded' event trigger offer generation -->
  pc.onnegotiationneeded = function () {
    pc.createOffer(localDescCreated, logError);
  }

  // 일단 원격 스트림이 도착하면 원격 비디오 엘리먼트 안에 그것을 보여줍니다. <!-- once remote stream arrives, show it in the remote video  -->element
  pc.onaddstream = function (evt) {
    remoteView.src = URL.createObjectURL(evt.stream);
  };

  // 로컬 스트림을 받으면 그것을 자체 뷰에서 보여주고 전송을 위해 추가합니다. <!-- get a local stream, show it in a self-view and add it to be sent -->
  navigator.getUserMedia({
    'audio': true,
    'video': true
  }, function (stream) {
    selfView.src = URL.createObjectURL(stream);
    pc.addStream(stream);
  }, logError);
}

function localDescCreated(desc) {
  pc.setLocalDescription(desc, function () {
    signalingChannel.send(JSON.stringify({
      'sdp': pc.localDescription
    }));
  }, logError);
}

signalingChannel.onmessage = function (evt) {
  if (!pc)
    start();

  var message = JSON.parse(evt.data);
  if (message.sdp)
    pc.setRemoteDescription(new RTCSessionDescription(message.sdp), function () {
      // if we received an offer, we need to answer
      if (pc.remoteDescription.type == 'offer')
        pc.createAnswer(localDescCreated, logError);
    }, logError);
  else
    pc.addIceCandidate(new RTCIceCandidate(message.candidate));
};

function logError(error) {
  log(error.name + ': ' + error.message);
}</pre>

<p>액션에서 제안/응답과 후보 교환 프로세스를 보기 위해서, <a href="http://simpl.info/rtcpeerconnection/">simpl.info/pc</a>의 '단일 페이지' 비디오 채팅 예제의 콘솔 로그를 살펴봅시다. 만약 여러분이 원한다면 chrome://webrtc-internals 페이지에서 WebRTC 시그널링의 완전한 덤프(Dump)나 상태를 다운로드할 수 있습니다.<!-- To see the offer/answer and candidate exchange processes in action, take a look at the console log for the 'single-page' video chat example at <a href="http://simpl.info/rtcpeerconnection/">simpl.info/pc</a>. If you want more, download a complete dump of WebRTC signaling and stats from the chrome://webrtc-internals page. --></p>

<h3 id="peer-discovery">Peer의 탐색<!-- Peer discovery --></h3>

<p>어떻게 내가 대화할 사람을 찾을 수 있을까요? &mdash;라고 말하는 것은 복잡한 방법입니다.<!-- This is fancy way of saying &mdash; how do I find someone to talk to? --></p>

<p>전화는 우리가 가진 전화번호와 디렉토리들에 호출을 합니다. 온라인 비디오 채팅과 메세지를 위해서도 우리는 신원과 참석 관리 시스템과 사용자들의 세션 초기화 방법이 필요합니다. WebRTC 앱들은 클라이언트들이 호출에 대한 시작이나 참여를 서로에게 신호할 수 있도록 방법이 필요합니다.<!-- For telephone calls we have telephone numbers and directories. For online video chat and messaging, we need identity and presence management systems, and a means for users to initiate sessions. WebRTC apps need a way for clients to signal to each other that they want to start or join a call. --></p>

<p>Peer 탐색 메커니즘은 WebRTC에 의해 정의되지 않으며 그렇게 할 수 있는 옵션도 없습니다. 절차는 다음과 같이 URL을 통해 이메일이나 메세지를 하는 것처럼 간단합니다. 

<a href="http://talky.io">talky.io</a>, <a href="http://tawk.com">tawk.com</a> 그리고 <a href="http://browsermeeting.com">browsermeeting.com</a>과 같은 비디오 채팅 어플리케이션들은 커스텀 링크의 공유를 통해 호출하여 사람들을 초대할 수 있습니다. 개발자 Chris Ball은 WebRTC 호출 시 참가자들간의 인스턴트 메세지, 이메일이나 집 비둘기와 같이 그들이 원하는 그 어떤 메세지 서비스에 의해서도 메타 데이터를 교환할 수 있도록 하는 <a href="http://blog.printf.net/articles/2013/05/17/webrtc-without-a-signaling-server/">serverless-webrtc</a>라는 아주 흥미로운 실험을 구축했습니다.<!-- Peer discovery mechanisms are not defined by WebRTC and we won't go into the options here. The process can be as simple as emailing or messaging a URL: for video chat applications such as <a href="http://talky.io">talky.io</a>, <a href="http://tawk.com">tawk.com</a> and <a href="http://browsermeeting.com">browsermeeting.com</a> you invite people to a call by sharing a custom link. Developer Chris Ball has built an intriguing <a href="http://blog.printf.net/articles/2013/05/17/webrtc-without-a-signaling-server/">serverless-webrtc</a> experiment that enables WebRTC call participants to exchange metadata by any messaging service they like, such as IM, email or homing pigeon. --></p>

<h2 id="how-can-i-build-a-signaling-service">어떻게 시그널링 서비스를 구축할 수 있을까요?<!-- How can I build a signaling service? --></h2>

<p>To reiterate: signaling protocols and mechanisms are not defined by WebRTC standards. Whatever you choose, you'll need an intermediary server to exchange signaling messages and application data between clients. Sadly, a web app cannot simply shout into the internet 'Connect me to my friend!' <br/> <br/> Thankfully signaling messages are small, and mostly exchanged at the start of a call. In testing with <a href="http://apprtc.appspot.com">apprtc.appspot.com</a> and <a href="http://samdutton-nodertc.jit.su/">samdutton-nodertc.jit.su</a> we found that, for a video chat session, a total of around 30–45 messages were handled by the signaling service, with a total size for all messages of around 10kB.</p>

<p>As well as being relatively undemanding in terms of bandwidth, WebRTC signaling services don't consume much processing or memory, since they only need to relay messages and retain a small amount of session state data (such as which clients are connected).</p>

<blockquote class="commentary talkinghead">
<strong>Note</strong>: the signaling mechanism used to exchange session metadata can also be used to communicate application data, such as messages between the app and users. It's just a messaging service!
</blockquote>

<h3 id="pushing-messages-from-the-server-to-the-client">Pushing messages from the server to the client</h3>

<p>A message service for signaling needs to be bidirectional: client to server and server to client. Bidirectional communication goes against the HTTP client/server request/response model, but various hacks such as <a href="https://en.wikipedia.org/wiki/Comet_(programming)">long polling</a> have been developed over many years in order to push data from a service running on a web server to a web app running in a browser.</p>

<p>More recently, the <a href="http://www.html5rocks.com/en/tutorials/eventsource/basics/">EventSource API</a> has been <a href="http://caniuse.com/#feat=eventsource">widely implemented</a>. This enables 'server-sent events': data sent from a web server to a browser client via HTTP. There's a simple demo at <a href="http://simpl.info/es">simpl.info/es</a>. EventSource is designed for one way messaging, but it can be used in combination with XHR to build a service for exchanging signaling messages: a signaling service passes on a message from a caller, delivered by XHR request, by pushing it via EventSource to the callee.</p>

<p><a href="http://www.html5rocks.com/en/tutorials/websockets/basics/">WebSocket</a> is a more natural solution, designed for full duplex client–server communication (messages can flow in both directions at the same time). One advantage of a signaling service built with pure WebSocket or Server-Sent Events (EventSource) is that the back-end for these APIs can be implemented on a variety of web frameworks common to most web hosting packages, for languages such as PHP, Python and Ruby.</p>

<p>About three quarters of browsers <a href="http://caniuse.com/#search=websocket">support WebSocket</a> and, more importantly, all browsers that support WebRTC also support WebSocket, both on desktop and mobile. <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS</a> should be used for all connections, to ensure messages cannot be intercepted unencrypted, and also to <a href="http://www.infoq.com/articles/Web-Sockets-Proxy-Servers">reduce problems with proxy traversal</a>. (For more information about WebSocket and proxy traversal see Ilya Grigorik's <a href="http://chimera.labs.oreilly.com/books/1230000000545/ch17.html#_http_upgrade_negotiation">WebRTC chapter</a> in the forthcoming O'Reilly's forthcoming <em>High Performance Browser Networking. </em>Peter Lubber's <a href="http://refcardz.dzone.com/refcardz/html5-websocket">WebSocket Cheat Sheet</a> has more information about WebSocket clients and servers.)</p>

<p>Signaling for the canonical <a href="http://apprtc.appspot.com">apprtc.appspot.com</a> WebRTC video chat application is accomplished via the <a href="https://developers.google.com/appengine/docs/java/channel/">Google App Engine Channel API</a>, which uses <a href="http://en.wikipedia.org/wiki/Comet_(programming)">Comet</a> techniques (long polling) to enable signaling with push communication between the App Engine backend and the web client. (There's a <a href="https://code.google.com/p/googleappengine/issues/detail?id=2535">long-standing bug</a> for App Engine to support WebSocket. <strong>Star the bug to vote it up!</strong>) There is a <a href="http://www.html5rocks.com/en/tutorials/webrtc/basics/#toc-simple">detailed code walkthrough</a> of this app in the <a href="http://www.html5rocks.com/en/tutorials/webrtc/basics/">HTML5 Rocks WebRTC article</a>.</p>

<figure>
  <img src="apprtc.jpg" alt="The apprtc.appspot.com video chat application" />
  <figcaption><a href="http://apprtc.appspot.com">apprtc</a> in action</figcaption>
</figure>

<p>It is also possible to handle signaling by getting WebRTC clients to poll a messaging server repeatedly via Ajax, but that leads to a lot of redundant network requests, which is especially problematic for mobile devices. Even after a session has been established, peers need to poll for signaling messages in case of changes or session termination by other peers. The <a href="http://webrtcbook.com">WebRTC Book</a> app example takes this option, with some optimizations for polling frequency.</p>

<h3 id="scaling-signaling">Scaling signaling</h3>

<p>Although a signaling service consumes relatively little bandwidth and CPU per client, signaling servers for a popular application may have to handle a lot of messages, with high levels of concurrency. WebRTC apps that get a lot of traffic need signaling servers able to handle considerable load. We won't discuss them here, but for high volume messaging there are a variety of high performance realtime messaging options available that can be used for signaling, such as <a href="http://zeromq.org/">ZeroMQ</a> (used by TokBox for their <a href="http://www.tokbox.com/blog/tokbox-builds-it%E2%80%99s-own-internal-messaging-infrastructure/">Rumour</a> service).</p>

<h3 id="building-a-signaling-service-with-socket.io-on-node">Building a signaling service with Socket.io on Node</h3>

<p>Below is code for a simple web application that uses a signaling service built with <a href="http://socket.io">Socket.io</a> on <a href="http://nodejs.org/">Node</a>. The design of Socket.io makes it simple to build a service to exchange messages, and Socket.io is particularly suited to WebRTC because of its built-in concept of 'rooms'.</p>

<p>Socket.io uses WebSocket with the following fallbacks: Adobe Flash Socket, AJAX long polling, AJAX multipart streaming, Forever Iframe and JSONP polling. It has been ported to various backends, but is perhaps best known for its Node version. We use Socket.io in the example below.</p>

<p>There's no WebRTC in this example: it's designed only to show how to build signaling into a web app. (See Coding WebRTC for signaling, above.) View the console log to see what's happening as clients join a room and exchange messages. Our <a href="https://bitbucket.org/webrtc/codelab">WebRTC codelab</a> gives step-by-step instructions how to integrate this example into a complete WebRTC video chat application. You can download the code from <a href="https://bitbucket.org/webrtc/codelab/src/master/complete/step5">step 5 of the codelab repo</a> or try it out live at <a href="http://samdutton-nodertc.jit.su/">samdutton-nodertc.jit.su</a>: open the URL in two browsers for video chat.</p>

<p>Here is the client, <em>index.html</em>:</p>

<pre class="prettyprint">&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;WebRTC client&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;script src='/socket.io/socket.io.js'&gt;&lt;/script&gt;
    &lt;script src='js/main.js'&gt;&lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre>

<p>...and the JavaScript file <em>main.js </em>referenced in the client:</p>

<pre class="prettyprint">var isInitiator;

room = prompt('Enter room name:');

var socket = io.connect();

if (room !== '') {
  console.log('Joining room ' + room);
  socket.emit('create or join', room);
}

socket.on('full', function (room){
  console.log('Room ' + room + ' is full');
});

socket.on('empty', function (room){
  isInitiator = true;
  console.log('Room ' + room + ' is empty');
});

socket.on('join', function (room){
  console.log('Making request to join room ' + room);
  console.log('You are the initiator!');
});

socket.on('log', function (array){
  console.log.apply(console, array);
});
</pre>

<p>The complete server app:</p>

<pre class="prettyprint">var static = require('node-static');
var http = require('http');
var file = new(static.Server)();
var app = http.createServer(function (req, res) {
  file.serve(req, res);
}).listen(2013);

var io = require('socket.io').listen(app);

io.sockets.on('connection', function (socket){

  // convenience function to log server messages to the client
  function log(){
    var array = ['&gt;&gt;&gt; Message from server: '];
    for (var i = 0; i &lt; arguments.length; i++) {
      array.push(arguments[i]);
    }
      socket.emit('log', array);
  }

  socket.on('message', function (message) {
    log('Got message:', message);
    // for a real app, would be room only (not broadcast)
    socket.broadcast.emit('message', message);
  });

  socket.on('create or join', function (room) {
    var numClients = io.sockets.clients(room).length;

    log('Room ' + room + ' has ' + numClients + ' client(s)');
    log('Request to create or join room ' + room);

    if (numClients === 0){
      socket.join(room);
      socket.emit('created', room);
    } else if (numClients === 1) {
      io.sockets.in(room).emit('join', room);
      socket.join(room);
      socket.emit('joined', room);
    } else { // max two clients
      socket.emit('full', room);
    }
    socket.emit('emit(): client ' + socket.id + ' joined room ' + room);
    socket.broadcast.emit('broadcast(): client ' + socket.id + ' joined room ' + room);

  });

});</pre>

<p>(You don't need to learn about node-static for this: it just makes the server simpler.)</p>

<p>To run this app on localhost, you need to have Node, socket.io and <a href="https://github.com/cloudhead/node-static">node-static</a> installed. Node can be downloaded from <a href="http://nodejs.org/">nodejs.org</a> (installation is straightforward and quick). To install socket.io and node-static, run Node Package Manager from a terminal in your application directory:</p>

<blockquote>

<p><code>npm install socket.io&lt;br/&gt; npm install node-static</code><br/></p>

</blockquote>

<p>To start the server, run the following command from a terminal in your application directory:</p>

<blockquote>

<p><code>node server.js</code><br/></p>

</blockquote>

<p>From your browser, open <em>localhost:2013</em>. Open a new tab page or window in any browser and open <em>localhost:2013</em> again. To see what's happening, check the console: in Chrome, you can access this via the Chrome DevTools with Command-Option-J or Ctrl-Shift-J.</p>

<p>Whatever approach you choose for signaling, your backend and client app will &mdash; at the very least &mdash; need to provide services similar to this example.</p>

<h3 id="using-rtcdatachannel-for-signaling">Using RTCDataChannel for signaling</h3>

<p>A signaling service is required to initiate a WebRTC session.</p>

<p>However, once a connection has been established between two peers, RTCDataChannel could, in theory, take over as the signaling channel. This might reduce latency for signaling &mdash; since messages fly direct &mdash; and help reduce signaling server bandwidth and processing costs.</p>

<h3 id="signaling-gotchas">Signaling gotchas</h3>

<ul>
  <li>RTCPeerConnection won't start gathering candidates until <em>setLocalDescription()</em> is called: this is mandated in the <a href="http://tools.ietf.org/html/draft-ietf-rtcweb-jsep-03#section-4.2.4">JSEP IETF draft</a>.</li>
  <li>Take advantage of Trickle ICE (see above): call <em>addIceCandidate() </em>as soon as candidates arrive.</li>

</ul>

<h3 id="readymade-signaling-servers">Readymade signaling servers</h3>

<p>If you don't want to roll your own, there are several WebRTC signaling servers available, which use Socket.io like the example above, and are integrated with WebRTC client JavaScript libraries:<br/></p>

<ul>
  <li><a href="https://github.com/webRTC/webRTC.io">webRTC.io</a>: one of the first abstraction libraries for WebRTC.</li>
  <li><a href="https://github.com/priologic/easyrtc">easyRTC</a>: a full-stack WebRTC package.</li>
  <li><a href="https://github.com/andyet/signalmaster">Signalmaster</a>: a signaling server created for use with the <a href="https://github.com/HenrikJoreteg/SimpleWebRTC">SimpleWebRTC</a> JavaScript client library.</li>

</ul>

<p>...and if you don't want to write any code at all, complete commercial WebRTC platforms are available from companies such as <a href="http://www.vline.com/">vLine</a>, <a href="http://tokbox.com/opentok">OpenTok</a> and <a href="https://wiki.asterisk.org/wiki/display/AST/Asterisk+WebRTC+Support">Asterisk</a>.</p>

<p>For the record, Ericsson built a <a href="https://labs.ericsson.com/blog/a-web-rtc-tutorial">signaling server using PHP on Apache</a> in the early days of WebRTC. This is now somewhat obsolete, but it's worth looking at the code if you're considering something similar.</p>

<h3 id="signaling-security">Signaling security</h3>

<blockquote class="commentary">
  <p>Security is the art of making nothing happen.</p>
  <p>&mdash; <a href="http://t.co/S9cUM7bVfd" title="Salman Rushdie reading and discussing Donald Barthelme's story, The Bodyguard">Salman Rushdie</a></p>
</blockquote>

<p>Encryption is <a href="http://www.ietf.org/proceedings/82/slides/rtcweb-13.pdf">mandatory</a> for all WebRTC components.</p>

<p>However, signaling mechanisms aren't defined by WebRTC standards, so it's up to you make signaling secure. If an attacker manages to hijack signaling, they can stop sessions, redirect connections and record, alter or inject content.</p>

<p>The most important factor in securing signaling is to use secure protocols, HTTPS and WSS (i.e TLS), which ensure that messages cannot be intercepted unencrypted. Also be careful not to broadcast signaling messages in a way that they can be accessed by other callers using the same signaling server.</p>

<p class="notice fact">To secure a WebRTC app it is <strong>absolutely imperative</strong> that signaling uses <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS</a>.</p>

<h2 id="after-signaling-using-ice-to-cope-with-nats-and-firewalls">After signaling: using ICE to cope with NATs and firewalls</h2>

<p>For metadata signaling, WebRTC apps use an intermediary server, but for actual media and data streaming once a session is established, RTCPeerConnection attempts to connect clients directly: peer to peer.</p>

<p>In a simpler world, every WebRTC endpoint would have a unique address that it could exchange with other peers in order to communicate directly.</p>

<figure>
  <img src="p2p.png" alt="Simple peer to peer connection" />
  <figcaption>A world without NATs and firewalls</figcaption>
</figure>

<p>In reality most devices live behind one or more layers of <a href="http://www.howstuffworks.com/nat.htm">NAT</a>, some have anti-virus software that blocks certain ports and protocols, and many are behind proxies and corporate firewalls. A firewall and NAT may in fact be implemented by the same device, such as a home wifi router.</p>

<figure>
  <img src="nat.png" alt="Peers behind NATs and firewalls" />
  <figcaption>The real world</figcaption>
</figure>

<p>WebRTC apps can use the <a href="https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment">ICE</a> framework to overcome the complexities of real-world networking. To enable this to happen, your application must pass ICE server URLs to RTCPeerConnection, as described below.</p>

<p>ICE tries to find the best path to connect peers. It tries all possibilities in parallel and chooses the most efficient option that works. ICE first tries to make a connection using the host address obtained from a device's operating system and network card; if that fails (which it will for devices behind NATs) ICE obtains an external address using a STUN server, and if that fails, traffic is routed via a TURN relay server.</p>

<p>In other words:</p>

<ul>
  <li>A STUN server is used to get an external network address.</li>
  <li>TURN servers are used to relay traffic if direct (peer to peer) connection fails.</li>

</ul>

<p>Every TURN server supports STUN: a TURN server is a STUN server with added relaying functionality built in. ICE also copes with the complexities of NAT setups: in reality, NAT 'hole punching' may require more than just a public IP:port address.</p>

<p>URLs for STUN and/or TURN servers are (optionally) specified by a WebRTC app in the <em>iceServers</em> configuration object that is the first argument to the RTCPeerConnection constructor. For <a href="http://apprtc.appspot.com">apprtc.appspot.com</a> that value looks like this:</p>

<pre class="prettyprint">{
  'iceServers': [
    {
      'url': 'stun:stun.l.google.com:19302'
    },
    {
      'url': 'turn:192.158.29.39:3478?transport=udp',
      'credential': 'JZEOEt2V3Qb0y27GRntt2u2PAYA=',
      'username': '28224511:1379330808'
    },
    {
      'url': 'turn:192.158.29.39:3478?transport=tcp',
      'credential': 'JZEOEt2V3Qb0y27GRntt2u2PAYA=',
      'username': '28224511:1379330808'
    }
  ]
}</pre>

<p>Once RTCPeerConnection has that information, the ICE magic happens automatically: RTCPeerConnection uses the ICE framework to work out the best path between peers, working with STUN and TURN servers as necessary.</p>

<h3 id="more-about-stun">STUN</h3>

<p><a href="http://www.howstuffworks.com/nat.htm">NAT</a>s provide a device with an IP address for use within a private local network, but this address can't be used externally. Without a public address, there's no way for WebRTC peers to communicate. To get around this problem WebRTC uses <a href="https://en.wikipedia.org/wiki/STUN">STUN</a>.</p>

<p>STUN servers live on the public internet and have one simple task: check the IP:port address of an incoming request (from an application running behind a NAT) and send that address back as a response. In other words, the application uses a STUN server to discover its IP:port from a public perspective. This process enables a WebRTC peer to get a publicly accessible address for itself, and then pass that on to another peer via a signaling mechanism, in order to set up a direct link. (In practice, different NATs work in different ways, and there may be multiple NAT layers, but the principle is still the same.)</p>

<p>STUN servers don't have to do much or remember much, so relatively low-spec STUN servers can handle a large number of requests.</p>

<p>Most WebRTC calls successfully make a connection using STUN: 86%, according to <a href="http://webrtcstats.com/">webrtcstats.com</a>, though this can be less for calls between peers behind firewalls and complex NAT configurations.</p>

<figure>
  <img src="stun.png" alt="Peer to peer connection using a STUN server" />
  <figcaption>Using STUN servers to get public IP:port addresses</figcaption>
</figure>

<h3 id="turn">TURN</h3>

<p>RTCPeerConnection tries to set up direct communication between peers over UDP. If that fails, RTCPeerConnection resorts to TCP. If that fails, TURN servers can be used as a fallback, relaying data between endpoints.</p>

<p><strong>Just to reiterate: TURN is used to relay audio/video/data streaming between peers, not signaling data!</strong></p>

<p>TURN servers have public addresses, so they can be contacted by peers even if the peers are behind firewalls or proxies. TURN servers have a conceptually simple task &mdash; to relay a stream &mdash; but, unlike STUN servers, they inherently consume a lot of bandwidth. In other words, TURN servers need to be beefier.</p>

<figure>
  <img src="turn.png" alt="Peer to peer connection using a STUN server" />
  <figcaption>The full Monty: STUN, TURN and signaling</figcaption>
</figure>

<p>This diagram shows TURN in action: pure STUN didn't succeed, so each peer resorts to using a TURN server.</p>

<h3 id="deploying-stun-and-turn-servers">Deploying STUN and TURN servers</h3>

<p>For testing, Google runs a public STUN server, stun.l.google.com:19302, as used by <a href="http://apprtc.appspot.com">apprtc.appspot.com</a>. For a production STUN/TURN service, we recommend using the rfc5766-turn-server; source code for STUN and TURN servers is available from <a href="https://code.google.com/p/rfc5766-turn-server/">code.google.com/p/rfc5766-turn-server</a>, which also provides links to several sources of information about server installation. A <a href="https://groups.google.com/forum/#!msg/discuss-webrtc/X-OeIUC0efs/XW5Wf7Tt1vMJ">VM image for Amazon Web Services</a> is also available.</p>

<p>An alternative TURN server is restund, available as <a href="http://www.creytiv.com/restund.html">source code</a> and also for AWS. Below are instructions how to set up restund on Google Compute Engine.</p>
<ol>
  <li>Open firewall as necessary, for tcp=443, udp/tcp=3478</li>
  <li>Create four instances, one for each public IP, Standard Ubuntu 12.06 image</li>
  <li>Set up local firewall config (allow ANY from ANY)</li>

  <li style="line-height: 1.8em;">Install tools:<br />
    <code>sudo apt-get install make<br />
    sudo apt-get install gcc</code>
  </li>
  <li style="line-height: 1.8em;">Download and build restund:<br />
      libre: <a href="http://creytiv.com/re.html" title="libre">creytiv.com/re.html</a><br />
      restund: <a href="http://creytiv.com/restund.html" title="">creytiv.com/restund.html</a>
  </li>
  <li>Update <em>restund/mk</em> to disable IPv6 due to build error (HAVE_INET6)</li>
  <li>Run <code>sudo make install</code> for libre and restund</li>
  <li style="line-height: 1.8em;">Configure restund:<br />
    Set <em>LD_LIBRARY_PATH</em><br />
    Copy <em>restund.conf</em> to <em>/etc/restund.conf</em><br />
    Set <em>restund.conf</em> to use the right 10. IP address
  </li>
  <li>Run restund</li>
  <li>Test using stund client from remote machine: <code>./client <em>IP:port</em></code></li>
</ol>
<h2 id="beyond-one-to-one-multi-party-webrtc">Beyond one-to-one: multi-party WebRTC</h2>

<p>You may also want to take a look at Justin Uberti's proposed IETF standard for a <a href="http://tools.ietf.org/html/draft-uberti-rtcweb-turn-rest-00" title="IETF draft: A REST API For Access To TURN Services">REST API for access to TURN Services</a>.</p>

<p>It's easy to imagine use cases for media streaming that go beyond a simple one-to-one call: for example, video conferencing between a group of colleagues, or a public event with one speaker and hundreds (or millions) of viewers.</p>

<p>A WebRTC app can use multiple RTCPeerConnections so to that every endpoint connects to every other endpoint in a mesh configuration. This is the approach taken by apps such as <a href="http://talky.io">talky.io</a>, and works remarkably well for a small handful of peers. Beyond that, processing and bandwidth consumption becomes excessive, especially for mobile clients.</p>

<figure>
  <img src="mesh.png" alt="Mesh: small N-way call" />
  <figcaption>Full mesh topology: everyone connected to everyone</figcaption>
</figure>

<p>Alternatively, a WebRTC app could choose one endpoint to distribute streams to all others, in a star configuration. It would also be possible to run a WebRTC endpoint on a server and roll your own redistribution mechanism (a <a href="https://code.google.com/p/webrtc/source/browse/#svn%2Ftrunk%2Ftalk">sample client application</a> is provided by webrtc.org).</p>

<h3 id="multipoint-control-unit">Multipoint Control Unit</h3>

<p>A better option for a large number of endpoints is to use a <a href="https://en.wikipedia.org/wiki/Multipoint_control_unit">Multipoint Control Unit</a> (MCU). This is a server that works as a bridge to distribute media between a large numbers of participants. MCUs can cope with different resolutions, codecs and frame rates within a video conference, handle transcoding, do selective stream forwarding, and mix or record audio and video. For multi-party calls, there are a number of issues to consider: in particular, how to display multiple video inputs and mix audio from multiple sources. Cloud platforms such as <a href="http://www.vline.com/">vLine</a> also attempt to optimise traffic routing.</p>

<figure>
  <img src="mcu.jpg" alt="Rear view of Cisco MCU5300" />
  <figcaption>The back of a <a href="http://cisco.com/en/US/products/ps12283">Cisco MCU</a></figcaption>
</figure>

<p><a href="http://lynckia.com/">Licode</a> (previously know as Lynckia) produces an open source MCU for WebRTC; OpenTok has <a href="http://www.tokbox.com/blog/mantis-next-generation-cloud-technology-for-webrtc/">Mantis</a>.</p>

<p>In Chrome 31 and above, a MediaStream from one RTCPeerConnection can be used as the input for another: there's a demo at <a href="http://simpl.info/rtcpeerconnection/multi">simpl.info/multi</a>. This could enable interesting architectures, since a web app can choose which client(s) to connect to.</p>

<h2 id="beyond-browsers-voip-telephones-and-messaging">Beyond browsers: VoIP, telephones and messaging</h2>

<p>The standardized nature of WebRTC makes it possible to establish communication between a WebRTC app running in a browser and a device or platform running on another communication platform, such as a telephone or a video conferencing systems.</p>

<p><a href="http://en.wikipedia.org/wiki/Session_Initiation_Protocol">SIP</a> is a signaling protocol used by VoIP and video conferencing systems. To enable communication between a WebRTC web app and a SIP client such as a video conferencing system, WebRTC needs a proxy server to mediate signaling. Signaling must flow via the gateway but, once communication has been established, SRTP traffic (video and audio) can flow directly peer to peer.</p>

<p><a href="http://en.wikipedia.org/wiki/Public_switched_telephone_network">PSTN</a>, the Public Switched Telephone Network, is the <a href="http://en.wikipedia.org/wiki/Circuit_switching">circuit switched</a> network of all 'plain old' analogue telephones. For calls between WebRTC web apps and telephones, traffic must go through a PSTN gateway. Likewise, WebRTC web apps need an intermediary XMPP server to communicate with <a href="http://en.wikipedia.org/wiki/Jingle_(protocol)">Jingle</a> endpoints such as IM clients. Jingle was developed by Google as an extension to XMPP to enable voice and video for messaging services: current WebRTC implementations are based on the C++ <a href="https://developers.google.com/talk/libjingle/">libjingle</a> library, an implementation of Jingle initially developed for Google Talk.</p>

<p>A number of apps, libraries and platforms make use of WebRTC's ability to communicate with the outside world:</p>

<ul>
  <li><a href="https://code.google.com/p/sipml5/">sipML5</a>: an open source JavaScript SIP client</li>
  <li><a href="http://www.jssip.net/">jsSIP</a>: JavaScript SIP library</li>
  <li><a href="http://phono.com/">Phono</a>: open source JavaScript phone API, built as a plugin</li>
  <li><a href="http://zingaya.com/product/">Zingaya</a>: an embeddable phone widget</li>
  <li><a href="http://www.twilio.com/">Twilio</a>: voice and messaging</li>
  <li><a href="http://www.uberconference.com/">Uberconference</a>: conferencing</li>

</ul>

<p>The sipML5 developers have also built the <a href="https://code.google.com/p/webrtc2sip/">webrtc2sip</a> gateway. Tethr and Tropo have demonstrated <a href="http://tethr.tumblr.com/post/25513708436/tethr-and-tropo-in-the-google-i-o-sandbox">a framework for disaster communications</a> 'in a briefcase', using an <a href="http://en.wikipedia.org/wiki/OpenBTS">OpenBTS cell</a> to enable communications between feature phones and computers via WebRTC. Telephone communication without a carrier!</p>

<!-- <h2 id="and-finally">...and finally</h2>

<p>The infrastructure requirements for WebRTC applications are inherently more complex than for simpler web apps.</p>

<p>Signaling and peer discovery services are not part of the WebRTC specs, and that might seem to make WebRTC applications more difficult to develop, but this approach gives you considerable power to tailor an application to meet your needs. Likewise, the ICE framework provides well-established techniques to get around real-world problems.</p> -->

<h2 id="find-out-more">Find out more</h2>

<p>WebRTC <a href="https://bitbucket.org/webrtc/codelab">codelab</a>: step-by-step instructions how to build a video and text chat application, using a Socket.io signaling service running on Node.</p>

<p><a href="http://www.youtube.com/watch?v=p2HzZkd2A40">2013 Google I/O WebRTC presentation</a> with WebRTC tech lead, Justin Uberti.</p>

<p>The <a href="http://webrtcbook.com">WebRTC Book</a> gives a lot of detail about data and signaling pathways, and includes a number of detailed network topology diagrams.</p>

<p><a href="http://www.tokbox.com/blog/webrtc-and-signaling-what-two-years-has-taught-us/">WebRTC and Signaling: What Two Years Has Taught Us</a>: TokBox blog post about why leaving signaling out of the spec was a good idea.</p>

<p>Ilya Grigorik's <a href="http://chimera.labs.oreilly.com/books/1230000000545/ch18.html">WebRTC chapter</a> in O'Reilly's forthcoming <em>High Performance Browser Networking</em>.</p>


{% endblock %}
